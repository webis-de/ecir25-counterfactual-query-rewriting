\title{Counterfactual Query Rewriting \\ to Use Historical Relevance Feedback}
%\title{Query Reformulation for Historical Relevance Data}
%\title{Query Reformulation for Recurring Search Queries}
%\title{Query Reformulation for Recurring Web Search Queries}
%\title{Rewriting Queries for Incorporating Historical Relevance Data}

%\titlerunning{Abbreviated paper title}

\author{No author given}
%
\authorrunning{No author given}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{No institute given}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
When a retrieval system receives a query it has encountered before, previous relevance feedback like clicks or explicit judgments can help to return good results. However, the content of a previously relevant document may have changed, or the document might not be available anymore. In this paper, we propose to counterfactually assume that the relevant versions of the documents are still part of the retrieval collection (i.e., we artificially include them). Against this slightly changed collection, we derive so-called keyqueries for the previously relevant document variants---i.e., queries that return the relevant document variants in the top ranks. From the keyqueries' results, we then remove the artificially included document variants to derive the final retrieval result. Our evaluation in the scenario of the CLEF LongEval shared task shows that \ldots

\keywords{Query Rewriting \and Keyqueries \and Longitudinal evaluation}
\end{abstract}
