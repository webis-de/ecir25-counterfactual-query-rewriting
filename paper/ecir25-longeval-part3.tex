\section{Query Rewriting on Historical Relevance Feedback}

We present three approaches that incorporate historical relevance feedback for previously seen queries by increasing maturity, from \Ni boosting (can not generalize), over \Nii relevance feedback (might underfit), towards \Niii keyqueries (trade-off under- vs. overfitting). These three approaches are frequently applied in diverse retrieval scenarios (see Section~\ref{sec:related-work}), but we first transfer them to a scenario with historical relevance feedback, thereby substantially enriching the domains in which they can be applied.

All of our approaches use a set $H$~of historical relevance feedback. For each observation $(q, d, t) \in H$, $rel(q, d, t)$ specifies the (graded) relevance judgment for document~$d$ for query~$q$ at timestamp~$t$, potentially derived via click models. As exemplified in Table~\ref{table-examples}, document~$d$ might be deleted or substantially changed from the current corpus, which is why our relevance feedback and keyquery approaches counterfactually use the version of the document at timestamp $t$ where the relevance observation was made.

\paragraph{Boosting Previously Relevant Documents.} Given a ranking~$r$ obtained by some retrieval system and a set of historical relevance feedback, the qrel boost method directly boosts documents by their historical relevance label, no matter how much they changed or how old the historical relevance feedback is.


that are known to be relevant from past points in time up based on a weighting factor $\lambda^2$ and all known and not relevant query document pairs down by $(1-\lambda)^2$. Additionally, since the LongEval test collection has graded relevance labels, the score of all highly relevant query document pairs is additionally multiplied by $\mu$. If more than one previous point in time is used for the boosting, the score of a query document pair is repeatedly multiplied by the boost. While this approach appears to be highly effective~\cite{alkhalifa:2024,keller:2024b}, it can not generalize to new documents and is therefore not effective for the cross-validation and only included as an upper bound naive baseline.


\paragraph{Previously Relevant Documents as Explicit Relevance Feedback.} Improving on this baseline, a tf-idf query expansion based on previously relevant documents wes tested. Instead of directly boosting known relevant query document pairs, the top 10 tf-idf terms from the relevant documents are used to expand the original query. The expanded query is then used to query the corpus with BM25. Like the qrel boost approach before, the tf-idf query expansion also only affects topics that are already known but can generalize to new documents.


\paragraph{Keyqueries for Previously Relevant Documents.}

