\section{Query Rewriting on Historical Relevance Feedback}

We present three approaches that incorporate historical relevance feedback for previously seen queries by increasing maturity, from \Ni boosting (can not generalize), over \Nii relevance feedback (might underfit), towards \Niii keyqueries (trade-off under- vs. overfitting). These three approaches are frequently applied in diverse retrieval scenarios (see Section~\ref{sec:related-work}). However, we are the first to transfer them to a scenario with historical relevance feedback, thereby substantially enriching the domains in which they can be applied.

All of our approaches use a set $H$~of historical relevance feedback. For each observation $(q, d, t) \in H$, $rel(q, d, t)$ specifies the (graded) relevance judgment for document~$d$ for query~$q$ at timestamp~$t$, potentially derived via click models. As exemplified in Table~\ref{table-examples}, document~$d$ might be deleted or substantially changed from the current corpus, which is why our relevance feedback and keyquery approaches counterfactually use the version of the document at timestamp $t$ where the relevance observation was made.

\paragraph{Boosting Previously Relevant Documents.} Given a ranking~$r$ obtained by some retrieval system and a set of historical relevance feedback~$H$, the qrel boost method directly boosts documents by their historical relevance label, no matter how much they changed or how old the historical relevance feedback is. We apply boosting to increase the score of previously known relevant documents and decrease the score of previously known non-relevant documents. For a document~$d$ previously observed for the query~$q$ at the timestamps $t_{1}, \ldots, t_{k}$, we increase the score if it is relevant, respectively decrease the score if it is not-relevant at the corresponding timestamps using a weighting factor $\lambda^2$ and additionaly boost higly relevant or non-relevant documents by a factor of $\mu$, yielding a bosted score of document~$d$ in ranking~$r$ by:
\begin{equation}
\sum\limits_{t \in \{t_{1}, \ldots, t_{k}\}} \lambda^2 \cdot \mu \cdot rel(q,d,t)
\end{equation}

While this qrel boosting is highly effective when documents do not change~\cite{alkhalifa:2024,keller:2024b}, it can not generalize to new or deleted documents.


\paragraph{Previously Relevant Documents as Explicit Relevance Feedback.} Improving on this baseline, a tf-idf query expansion based on previously relevant documents wes tested. Instead of directly boosting known relevant query document pairs, the top 10 tf-idf terms from the relevant documents are used to expand the original query. The expanded query is then used to query the corpus with BM25. Like the qrel boost approach before, the tf-idf query expansion also only affects topics that are already known but can generalize to new documents.


\paragraph{Keyqueries for Previously Relevant Documents.}

