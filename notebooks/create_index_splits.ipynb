{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.10 (build: craigm 2024-08-22 17:33), helper_version=0.0.8]\n",
      "/Users/jueri/dev/conf25-counterfactual-query-rewriting/notebooks/../src/create_index.py:9: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "The following code will have the same effect:\n",
      "pt.java.add_package('com.github.terrierteam', 'terrier-prf', '-SNAPSHOT')\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "from src.create_index import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data\"\n",
    "RESULTS_PATH = BASE_PATH + \"/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_PATH + \"/LongEval/metadata.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sub_collection(sub_collection, topics, queryid_map, qrels, k=3):\n",
    "    overlap = {sub_collection: []}\n",
    "    topics_with_to_few_docs = []\n",
    "    valids_topics = []\n",
    "    \n",
    "    folds = {}\n",
    "    for i in range(0, k):\n",
    "        folds[i] = {\n",
    "            \"train\": set(),\n",
    "            \"test\": set()\n",
    "        }\n",
    "        \n",
    "    # Filter relevant documents for logging only\n",
    "    rel_docs = qrels.merge(topics, on=\"qid\")\n",
    "    rel_docs = rel_docs[rel_docs[\"relevance\"] > 0]\n",
    "    print(\"\\nDocs rel for more topics:\", rel_docs.duplicated(subset=[\"docno\"]).sum() , \"/\", len(rel_docs))\n",
    "    \n",
    "    \n",
    "    # Perform splits on topic level\n",
    "    for topic in queryid_map.keys():\n",
    "        # Get relevant documents for topic\n",
    "        rel_docs = qrels.merge(topics, on=\"qid\")\n",
    "        rel_docs = rel_docs[rel_docs[\"relevance\"] > 0]\n",
    "        rel_docs = rel_docs[rel_docs[\"qid\"]==topic]\n",
    "        \n",
    "        overlap[sub_collection].append(len(rel_docs))            \n",
    "        \n",
    "        # If we have fewer relevants docs than k, we skip this topic \n",
    "        if len(rel_docs) < k: \n",
    "            topics_with_to_few_docs.append(topic)\n",
    "            continue\n",
    "        else:\n",
    "            valids_topics.append(topic)\n",
    "\n",
    "        # split\n",
    "        kf = KFold(n_splits=k)\n",
    "        kf.get_n_splits(rel_docs)\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(rel_docs)):\n",
    "            train_ids = rel_docs.iloc[train_index][\"docno\"].to_list()\n",
    "            test_ids = rel_docs.iloc[test_index][\"docno\"].to_list()\n",
    "            \n",
    "            allready_in_train = folds[i][\"train\"].intersection(test_ids)\n",
    "            allready_in_test = folds[i][\"test\"].intersection(train_ids)\n",
    "            \n",
    "            # update folds to ensure each fold has unique documents\n",
    "            processed = set()\n",
    "            for test_id in allready_in_train:\n",
    "                test_ids.remove(test_id)\n",
    "                processed.add(test_id)\n",
    "                \n",
    "                # add a train doc to test if possible to maintain balance\n",
    "                if len(allready_in_test) > 0:\n",
    "                    train_id = allready_in_test.pop()\n",
    "                    train_ids.remove(train_id)\n",
    "                    \n",
    "            allready_in_train -= processed\n",
    "            \n",
    "            # repeat for new train split\n",
    "            for train_id in allready_in_test:\n",
    "                train_ids.remove(train_id)\n",
    "                \n",
    "                # add a test doc to train if possible to maintain balance\n",
    "                if len(allready_in_train) > 0:\n",
    "                    test_id = allready_in_train.pop()\n",
    "                    test_ids.remove(test_id)\n",
    "\n",
    "            folds[i][\"test\"].update(test_ids)\n",
    "            folds[i][\"train\"].update(train_ids)\n",
    "            \n",
    "    \n",
    "    # report on folds\n",
    "    for i in range(0, k):\n",
    "        overlap = len(folds[i][\"train\"].intersection(folds[i][\"test\"])) \n",
    "        train_size = len(folds[i][\"train\"])\n",
    "        test_size = len(folds[i][\"test\"])\n",
    "        ratio = train_size / (train_size + test_size)\n",
    "        print(f\"Fold {i}: train size: {train_size}, test size: {test_size}, overlap: {overlap}, ratio: {ratio:.2f}\")\n",
    "        \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docs rel for more topics: 565 / 3370\n",
      "Fold 0: train size: 535, test size: 348, overlap: 0, ratio: 0.61\n",
      "Fold 1: train size: 592, test size: 291, overlap: 0, ratio: 0.67\n",
      "Fold 2: train size: 639, test size: 244, overlap: 0, ratio: 0.72\n",
      "\n",
      "Docs rel for more topics: 683 / 3835\n",
      "Fold 0: train size: 570, test size: 380, overlap: 0, ratio: 0.60\n",
      "Fold 1: train size: 651, test size: 299, overlap: 0, ratio: 0.69\n",
      "Fold 2: train size: 679, test size: 271, overlap: 0, ratio: 0.71\n",
      "\n",
      "Docs rel for more topics: 1296 / 4362\n",
      "Fold 0: train size: 544, test size: 313, overlap: 0, ratio: 0.63\n",
      "Fold 1: train size: 577, test size: 280, overlap: 0, ratio: 0.67\n",
      "Fold 2: train size: 593, test size: 264, overlap: 0, ratio: 0.69\n",
      "\n",
      "Docs rel for more topics: 580 / 2689\n",
      "Fold 0: train size: 476, test size: 263, overlap: 0, ratio: 0.64\n",
      "Fold 1: train size: 494, test size: 245, overlap: 0, ratio: 0.67\n",
      "Fold 2: train size: 508, test size: 231, overlap: 0, ratio: 0.69\n",
      "\n",
      "Docs rel for more topics: 2337 / 10259\n",
      "Fold 0: train size: 1005, test size: 586, overlap: 0, ratio: 0.63\n",
      "Fold 1: train size: 1062, test size: 529, overlap: 0, ratio: 0.67\n",
      "Fold 2: train size: 1115, test size: 476, overlap: 0, ratio: 0.70\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "sub_collections = [\"t1\", \"t2\", \"t3\", \"t4\", \"t5\"]  # we skip t0 as it is the base collection and has no history\n",
    "splits = {}\n",
    "\n",
    "for sub_collection in sub_collections:\n",
    "    splits[sub_collection] = {}\n",
    "    # Load data for sub-collection\n",
    "    topics, qrels, docid_map_patch, queryid_map = load_data(sub_collection)\n",
    "    \n",
    "    # for pyterrier \n",
    "    topics[\"query\"] = topics[\"query\"].str.replace(\"'\", \"\").replace(\"/\", \"\")\n",
    "    \n",
    "    # Create Folds\n",
    "    folds = split_sub_collection(sub_collection, topics, queryid_map, qrels, k=3)\n",
    "     \n",
    "    for fold_no in range(0, k):\n",
    "        splits[sub_collection][fold_no] = {\n",
    "            \"train\": list(folds[fold_no][\"train\"]),\n",
    "            \"test\": list(folds[fold_no][\"test\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_PATH + \"/splits.json\", \"w\") as f:\n",
    "    f.write(json.dumps(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
